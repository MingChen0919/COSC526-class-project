{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pyspark\n",
    "# from pyspark.sql import SQLContext\n",
    "# \n",
    "# # create spark contexts\n",
    "# sc = pyspark.SparkContext()\n",
    "# sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neccessary modules and python files\n",
    "* **langid**\n",
    "* **nltk**\n",
    "\n",
    "### Install **langid**\n",
    "\n",
    "```\n",
    "pip install langid\n",
    "```\n",
    "\n",
    "### Download nltk\n",
    "\n",
    "* install **nltk** module\n",
    "```\n",
    "pip install nltk\n",
    "```\n",
    "\n",
    "* download corpora\n",
    "```\n",
    "# enter python interactive environment\n",
    "python\n",
    "# type python script\n",
    "from ntlk import download\n",
    "download()\n",
    "```\n",
    "\n",
    "\n",
    "### Get `preproc.py`\n",
    "* Reference: https://github.com/dreyco676/nlp_spark\n",
    "* Get `preproc.py`: `wget https://raw.githubusercontent.com/dreyco676/nlp_spark/master/preproc.py`\n",
    "* `preproc.py` has to be in the same directory with your *ipynb* file\n",
    "\n",
    "### Get practice data\n",
    "\n",
    "```\n",
    "git clone https://github.com/dreyco676/nlp_spark.git\n",
    "cd nlp_spark/\n",
    "unzip data.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "import preproc as pp\n",
    "# Register all the functions in Preproc with Spark Context\n",
    "check_lang_udf = udf(pp.check_lang, StringType())\n",
    "remove_stops_udf = udf(pp.remove_stops, StringType())\n",
    "remove_features_udf = udf(pp.remove_features, StringType())\n",
    "tag_and_remove_udf = udf(pp.tag_and_remove, StringType())\n",
    "lemmatize_udf = udf(pp.lemmatize, StringType())\n",
    "check_blanks_udf = udf(pp.check_blanks, StringType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_classified = spark.read.csv('nlp_spark/data/raw_classified.txt', inferSchema=True, sep='\\t').toDF('text', 'id', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+\n",
      "|                text|                id|label|\n",
      "+--------------------+------------------+-----+\n",
      "|Fresh install of ...|        1018769417|  1.0|\n",
      "|Well. Now I know ...|       10284216536|  1.0|\n",
      "|\"Literally six we...|       10298589026|  1.0|\n",
      "|Mitsubishi i MiEV...|109017669432377344|  1.0|\n",
      "|'Cheap Eats in SL...|109642968603963392|  1.0|\n",
      "+--------------------+------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_classified.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove single/double quotes and space at the begining and end of string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "trim_quotes_and_space_udf = udf(lambda s: s.strip().strip('\"').strip(\"'\"), StringType())\n",
    "raw_classified_v1 = raw_classified.withColumn('text', trim_quotes_and_space_udf(raw_classified.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+\n",
      "|                text|                id|label|\n",
      "+--------------------+------------------+-----+\n",
      "|Fresh install of ...|        1018769417|  1.0|\n",
      "|Well. Now I know ...|       10284216536|  1.0|\n",
      "|Literally six wee...|       10298589026|  1.0|\n",
      "|Mitsubishi i MiEV...|109017669432377344|  1.0|\n",
      "|Cheap Eats in SLP...|109642968603963392|  1.0|\n",
      "+--------------------+------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "Total rows: 115886\n"
     ]
    }
   ],
   "source": [
    "raw_classified_v1.show(5)\n",
    "print('Total rows: {}'.format(raw_classified_v1.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"Cheap Eats in SLP' - http://t.co/4w8gRp7\""
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_classified_v1.select('text').toPandas()['text'][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check string length in column 'text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "string_length_udf = udf(lambda s: len(s), IntegerType())\n",
    "raw_classified_v2 = raw_classified_v1.withColumn('text_length', string_length_udf(raw_classified_v1.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----+-----------+\n",
      "|      text|                id|label|text_length|\n",
      "+----------+------------------+-----+-----------+\n",
      "|   awesome|         882098800|  1.0|          7|\n",
      "|  City Wok|665255511273570305|  1.0|          8|\n",
      "| #iknowhow|537734337655889921|  1.0|          9|\n",
      "|It's cold.|159983261911760896|  1.0|         10|\n",
      "|Boarded :)|413084478760685568|  1.0|         10|\n",
      "+----------+------------------+-----+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+------------------+-----+-----------+\n",
      "|                text|                id|label|text_length|\n",
      "+--------------------+------------------+-----+-----------+\n",
      "|A girlfriend that...|424763466897846272|  1.0|        256|\n",
      "|Real boyfriends &...|429215572241285121|  1.0|        166|\n",
      "|RT @julieklausner...|199565254542376960|  1.0|        164|\n",
      "|Real boyfriends &...|418449856298889216|  1.0|        164|\n",
      "|Damn. I want to s...|445063125696401409|  1.0|        159|\n",
      "+--------------------+------------------+-----+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_classified_v2.orderBy('text_length').show(5)\n",
    "raw_classified_v2.orderBy('text_length', ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The minimum length is 7 and maximum length is 256. Therefore, no empty strings or None values in column 'text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+-----------+\n",
      "|                text|                id|label|text_length|\n",
      "+--------------------+------------------+-----+-----------+\n",
      "|Fresh install of ...|        1018769417|  1.0|         61|\n",
      "|Well. Now I know ...|       10284216536|  1.0|         85|\n",
      "|Literally six wee...|       10298589026|  1.0|        134|\n",
      "|Mitsubishi i MiEV...|109017669432377344|  1.0|         90|\n",
      "|Cheap Eats in SLP...|109642968603963392|  1.0|         40|\n",
      "+--------------------+------------------+-----+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_classified_v2.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How many labels are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|label|\n",
      "+-----+\n",
      "|  0.0|\n",
      "|  1.0|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_classified.select('label').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check values in column 'id'\n",
    "    + From the id sorted results, no NA, None values exist in column 'id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-----+-----------+\n",
      "|                text|       id|label|text_length|\n",
      "+--------------------+---------+-----+-----------+\n",
      "|Sorry! Account de...|797858706|  1.0|         59|\n",
      "|Yo am I imagining...|798243247|  1.0|        127|\n",
      "|Midnight coffee i...|798474877|  1.0|         48|\n",
      "|I'm sad that Mike...|799151574|  1.0|         45|\n",
      "|      Peter fixed it|799331338|  1.0|         14|\n",
      "+--------------------+---------+-----+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+------------------+-----+-----------+\n",
      "|                text|                id|label|text_length|\n",
      "+--------------------+------------------+-----+-----------+\n",
      "|White Dwarf 100 \"...|679856481798369282|  1.0|        123|\n",
      "|White Dwarf 100 \"...|679856481798369282|  1.0|        123|\n",
      "|White Dwarf 100 �...|679851755815985153|  1.0|        135|\n",
      "|RT @iwan0www: Pro...|679847620995579904|  1.0|        122|\n",
      "|RT @mikeolson: 9 ...|679847263238250497|  0.0|        140|\n",
      "+--------------------+------------------+-----+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_classified_v2.orderBy('id').show(5)\n",
    "raw_classified_v2.orderBy('id', ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('la', -101.41858577728271)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from langid import classify\n",
    "classify('this is a text, 中文')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function classify in module langid.langid:\n",
      "\n",
      "classify(instance)\n",
      "    Convenience method using a global identifier instance with the default\n",
      "    model included in langid.py. Identifies the language that a string is \n",
      "    written in.\n",
      "    \n",
      "    @param instance a text string. Unicode strings will automatically be utf8-encoded\n",
      "    @returns a tuple of the most likely language and the confidence score\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+-----------+\n",
      "|                text|                id|label|text_length|\n",
      "+--------------------+------------------+-----+-----------+\n",
      "|Fresh install of ...|        1018769417|  1.0|         61|\n",
      "|Well. Now I know ...|       10284216536|  1.0|         85|\n",
      "|Literally six wee...|       10298589026|  1.0|        134|\n",
      "|Mitsubishi i MiEV...|109017669432377344|  1.0|         90|\n",
      "|Cheap Eats in SLP...|109642968603963392|  1.0|         40|\n",
      "+--------------------+------------------+-----+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_classified_v2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict language and filter out those with less than 90% chance of being English\n",
    "lang_df = data_df.withColumn(\"lang\", check_lang_udf(data_df[\"text\"]))\n",
    "en_df = lang_df.filter(lang_df[\"lang\"] == \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "en_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+----+\n",
      "|                text|                id|label|lang|\n",
      "+--------------------+------------------+-----+----+\n",
      "|RT @goeentertain:...|665305154954989568|  1.0|  en|\n",
      "|Teforia Uses Mach...|660668007975268352|  1.0|  en|\n",
      "|   Apple TV or Roku?|       25842461136|  1.0|  en|\n",
      "|Finished http://t...|        9412369614|  1.0|  en|\n",
      "+--------------------+------------------+-----+----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "en_df.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove stop words to reduce dimensionality\n",
    "rm_stops_df = en_df.withColumn(\"stop_text\", remove_stops_udf(en_df[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- stop_text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rm_stops_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+----+--------------------+\n",
      "|                text|                id|label|lang|           stop_text|\n",
      "+--------------------+------------------+-----+----+--------------------+\n",
      "|RT @goeentertain:...|665305154954989568|  1.0|  en|RT @goeentertain:...|\n",
      "|Teforia Uses Mach...|660668007975268352|  1.0|  en|Teforia Uses Mach...|\n",
      "|   Apple TV or Roku?|       25842461136|  1.0|  en|      Apple TV Roku?|\n",
      "|Finished http://t...|        9412369614|  1.0|  en|Finished http://t...|\n",
      "+--------------------+------------------+-----+----+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rm_stops_df.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove other non essential words, think of it as my personal stop word list\n",
    "rm_features_df = rm_stops_df.withColumn(\"feat_text\", \\\n",
    "                                        remove_features_udf(rm_stops_df[\"stop_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- stop_text: string (nullable = true)\n",
      " |-- feat_text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rm_features_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+----+--------------------+--------------------+\n",
      "|                text|                id|label|lang|           stop_text|           feat_text|\n",
      "+--------------------+------------------+-----+----+--------------------+--------------------+\n",
      "|RT @goeentertain:...|665305154954989568|  1.0|  en|RT @goeentertain:...|  future blase   ...|\n",
      "|Teforia Uses Mach...|660668007975268352|  1.0|  en|Teforia Uses Mach...|teforia uses mach...|\n",
      "|   Apple TV or Roku?|       25842461136|  1.0|  en|      Apple TV Roku?|         apple  roku|\n",
      "|Finished http://t...|        9412369614|  1.0|  en|Finished http://t...|            finished|\n",
      "+--------------------+------------------+-----+----+--------------------+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rm_features_df.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tag the words remaining and keep only Nouns, Verbs and Adjectives\n",
    "tagged_df = rm_features_df.withColumn(\"tagged_text\", \\\n",
    "                                      tag_and_remove_udf(rm_features_df.feat_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- stop_text: string (nullable = true)\n",
      " |-- feat_text: string (nullable = true)\n",
      " |-- tagged_text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tagged_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+----+--------------------+--------------------+--------------------+\n",
      "|                text|                id|label|lang|           stop_text|           feat_text|         tagged_text|\n",
      "+--------------------+------------------+-----+----+--------------------+--------------------+--------------------+\n",
      "|RT @goeentertain:...|665305154954989568|  1.0|  en|RT @goeentertain:...|  future blase   ...| future blase vic...|\n",
      "|Teforia Uses Mach...|660668007975268352|  1.0|  en|Teforia Uses Mach...|teforia uses mach...| teforia uses mac...|\n",
      "|   Apple TV or Roku?|       25842461136|  1.0|  en|      Apple TV Roku?|         apple  roku|         apple roku |\n",
      "|Finished http://t...|        9412369614|  1.0|  en|Finished http://t...|            finished|           finished |\n",
      "+--------------------+------------------+-----+----+--------------------+--------------------+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tagged_df.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lemmatization of remaining words to reduce dimensionality & boost measures\n",
    "lemm_df = tagged_df.withColumn(\"lemm_text\", lemmatize_udf(tagged_df[\"tagged_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lemmatization of remaining words to reduce dimensionality & boost measures\n",
    "lemm_df = tagged_df.withColumn(\"lemm_text\", lemmatize_udf(tagged_df[\"tagged_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- stop_text: string (nullable = true)\n",
      " |-- feat_text: string (nullable = true)\n",
      " |-- tagged_text: string (nullable = true)\n",
      " |-- lemm_text: string (nullable = true)\n",
      " |-- is_blank: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remove all rows containing only blank spaces\n",
    "check_blanks_df = lemm_df.withColumn(\"is_blank\", check_blanks_udf(lemm_df[\"lemm_text\"]))\n",
    "no_blanks_df = check_blanks_df.filter(check_blanks_df[\"is_blank\"] == \"False\")\n",
    "no_blanks_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rename columns\n",
    "no_blanks_df = no_blanks_df.withColumn(\"text\",no_blanks_df.lemm_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dedupe important since alot of the tweets only differed by url's and RT mentions\n",
    "dedup_df = no_blanks_df.dropDuplicates(['text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# select only the columns we care about\n",
    "data_set = dedup_df.select('id', 'text','label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+-----+\n",
      "|                id|                text|label|\n",
      "+------------------+--------------------+-----+\n",
      "|        1546813742|              dragon|  1.0|\n",
      "|        1558492525|           hurt much|  1.0|\n",
      "|383221484023709697|seth blog word se...|  1.0|\n",
      "|660668007975268352|teforia use machi...|  1.0|\n",
      "+------------------+--------------------+-----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_set.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data_set.randomSplit([0.6, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import NaiveBayes, RandomForestClassifier \n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configure an ML pipeline, which consists of tree stages: tokenizer, hashingTF, and nb.\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
    "idf = IDF(minDocFreq=3, inputCol=\"features\", outputCol=\"idf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "nb = NaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, idf, nb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n",
      "|                text|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|           hurt much|  1.0|       1.0|\n",
      "|teforia use machi...|  1.0|       1.0|\n",
      "|              finish|  1.0|       1.0|\n",
      "|future blase vice...|  1.0|       1.0|\n",
      "|              divine|  1.0|       1.0|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select example rows to display.\n",
    "predictions.select(\"text\", \"label\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.912655971479501"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#paramGrid = ParamGridBuilder().addGrid(nb.smoothing, [0.0, 1.0]).build()\n",
    "# paramGrid = ParamGridBuilder().addGrid(rf.maxDepth,[4,8,10]).\\\n",
    "#                     addGrid(rf.impurity, ['entropy','gini']).build()\n",
    "\n",
    "\n",
    "# cv = CrossValidator(estimator=pipeline, \n",
    "#                     estimatorParamMaps=paramGrid, \n",
    "#                     evaluator=MulticlassClassificationEvaluator(), \n",
    "#                     numFolds=4)\n",
    "                    \n",
    "\n",
    "# #training_df.show(5)  \n",
    "# cvModel = cv.fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prediction = cvModel.transform(test_df)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
